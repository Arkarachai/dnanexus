#!/bin/bash
# geno_p 0.0.1
# Generated by dx-app-wizard.
#
# Parallelized execution pattern: Your app will generate multiple jobs
# to perform some computation in parallel, followed by a final
# "postprocess" stage that will perform any additional computations as
# necessary.
#
# Your job's input variables (if any) will be loaded as environment
# variables before this script runs.  Any array inputs will be loaded
# as bash arrays.
#
# Any code outside of main() or any other entry point is ALWAYS
# executed, followed by running the entry point itself.
#
# See https://wiki.dnanexus.com/Developer-Portal for tutorials on how
# to modify this file.

set -x

# install GNU parallel!
sudo sed -i 's/^# *\(deb .*backports.*\)$/\1/' /etc/apt/sources.list
sudo apt-get update
sudo apt-get install --yes parallel

function dl_split() {
	set -x
	WKDIR=$2
	OUTDIR=$3
	
	echo "'$1', '$2', '$3"
	cd $WKDIR
	fn=$(dx describe --name "$1")
	dx download "$1" -o "$fn"
	if test -z "$(ls $fn.tbi)"; then
		tabix -p vcf $fn
	fi
	
	TOT_MEM=$(free -m | grep "Mem" | awk '{print $2}')
	N_PROC=$(nproc --all)
		
	# Now, split by chromosome
	fn_base="$(echo $fn | sed 's/^\(.*\)\.vcf\(\.gz\)*$/\1/')"
	for chr in  $(tabix -l $fn); do
		java -d64 -Xms512m -Xmx$((TOT_MEM * 19 / (N_PROC * 20) ))m -jar /usr/share/GATK/GenomeAnalysisTK-3.3-0.jar \
		-T SelectVariants -L $chr \
		-V $fn \
		-R /usr/share/GATK/resources/human_g1k_v37_decoy.fasta \
		-o $OUTDIR/$fn_base.$chr.vcf.gz
	done
	
	rm "$fn"
	rm "$fn.tbi"
}

export -f dl_split

function dl_index() {
	set -x
	echo "'$1', '$2', '$3'"
	cd "$2"
	fn=$(dx describe --name "$1")
	dx download "$1" -o "$fn"
	if test -z "$(ls $fn.tbi)"; then
		tabix -p vcf $fn
	fi
	echo "$2/$fn" >> $3
}

export -f dl_index

function upload_files() {
	set -x
	fn_list=$1
	arg_fn=$2
	target_fn=$3
	
	chrom=$(head -1 $fn_list | sed -e 's/\.vcf\.gz$//' -e 's/.*\.//')
	process_args=""
	DO_UPLOAD=1
	if test "$target_fn"; then
		# subset the target file for only the target chromosome
		TARGET_SUBSET=$(mktemp -d)
		grep "^$chrom\W" $target_fn > $TARGET_SUBSET/targets.$chrom.bed
		if test $(cat $TARGET_SUBSET/targets.$chrom.bed | wc -l) -gt 0; then
			target_dxfn=$(dx upload --brief $TARGET_SUBSET/targets.$chrom.bed)
			process_args="$process_args -itarget_file:file=${target_dxfn}"
		else 
			DO_UPLOAD=0
		fi
	fi
	
	if test $DO_UPLOAD -ne 0; then
		for f in $(cat $fn_list); do
			echo "Uploading $f"
			vcf_fn=$(dx upload --brief $f)
			vcfidx_fn=$(dx upload --brief $f.tbi)
			process_args="$process_args -ivcf_files:array:file=${vcf_fn} -ivcfidx_files:array:file=${vcfidx_fn}"
		done
	fi
	
	echo "$process_args" >> $2
}

export -f upload_files

main() {

	export SHELL="/bin/bash"
	ADDL_CMD=""

	TARGET_FILE=""
	if test "$target_file"; then
		TARGET_DIR=$(mktemp -d)
		cd $TARGET_DIR
		dx download "$target_file" -o targets.bed
		cd -
		TARGET_FILE=$TARGET_DIR/targets.bed
	fi
	
	if test -z "$PREFIX"; then
		PREFIX="combined"
	fi
	
	WKDIR=$(mktemp -d)
	GVCF_SPLITDIR=$(mktemp -d)
	DXGVCF_LIST=$(mktemp)
	
	cd $WKDIR
	
	for i in "${!gvcfidxs[@]}"; do	
		dx download "${gvcfidxs[$i]}"
	done
	
	for i in "${!gvcfs[@]}"; do
		echo "${gvcfs[$i]}" >> $DXGVCF_LIST
	done
	
	# get the resources we need in /usr/share/GATK
	sudo mkdir -p /usr/share/GATK/resources
	sudo chmod -R a+rwX /usr/share/GATK
		
	#dx download $(dx find data --name "GenomeAnalysisTK-3.2-2.jar" --project $DX_RESOURCES_ID --brief) -o /usr/share/GATK/GenomeAnalysisTK-3.2-2.jar
	dx download $(dx find data --name "GenomeAnalysisTK-3.3-0.jar" --project $DX_RESOURCES_ID --brief) -o /usr/share/GATK/GenomeAnalysisTK-3.3-0.jar
	dx download $(dx find data --name "human_g1k_v37_decoy.fasta" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.fasta
	dx download $(dx find data --name "human_g1k_v37_decoy.fasta.fai" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.fasta.fai
	dx download $(dx find data --name "human_g1k_v37_decoy.dict" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.dict

	# Now, download and index in parallel, please
	parallel -u -j $(nproc --all) --gnu dl_split :::: $DXGVCF_LIST ::: $WKDIR ::: $GVCF_SPLITDIR
	
	# OK, now get a list of the individual files for each chromosome and output that to a file
	# merge all of the GVCFs by chromosome
	GVCF_MASTER_LIST=$(mktemp)
	for f in $(ls $GVCF_SPLITDIR | grep '\.vcf\.gz$' | sed 's/.*\.\([^.]*\)\.vcf.gz/\1/' | sort | uniq); do
		LIST_TMPF=$(mktemp)
		ls -1 $GVCF_SPLITDIR/*.$f.vcf.gz > $LIST_TMPF || true
		echo $LIST_TMPF >> $GVCF_MASTER_LIST
	done
	
	cat $GVCF_MASTER_LIST
	
	# now, upload everything and get the process arguments for subjobs
	PROCESS_ARG_FN=$(mktemp)
	parallel -u -j $(nproc --all) --gnu upload_files :::: $GVCF_MASTER_LIST ::: $PROCESS_ARG_FN ::: $TARGET_FILE
	
	# Kick off each of those subjobs
	CIDX=0
	pparg=""
	while read arg; do
		echo "INPUT ARGS=$arg"
		# Only do this if we have a job to run (can happen if no targets on a chromosome)
		if test "$arg"; then
			process_jobs[$CIDX]=$(dx-jobutil-new-job genotype_gvcfs -iPREFIX=$PREFIX.$CIDX $arg)
			pparg="$pparg -ivcf_files=${process_jobs[$CIDX]}:vcf_out -ivcfidx_files=${process_jobs[$CIDX]}:vcfidx_out"
			CIDX=$((CIDX + 1))
		fi
	done < $PROCESS_ARG_FN
	
	# OK, now we simply have to merge all of the VCF files together
	postprocess=$(dx-jobutil-new-job merge_vcf $pparg -iPREFIX:string="$PREFIX" --depends-on ${process_jobs[@]})
	dx-jobutil-add-output vcf "$postprocess:vcf_out" --class=jobref
	dx-jobutil-add-output vcfidx "$postprocess:vcfidx_out" --class=jobref
}

genotype_gvcfs() {

	export SHELL="/bin/bash"
	ADDL_CMD=""

	if test "$target_file"; then
		dx download "$target_file" -o targets.bed
		ADDL_CMD="-L $PWD/targets.bed"
	fi
	
	if test -z "$PREFIX"; then
		PREFIX="combined"
	fi
	
	WKDIR=$(mktemp -d)
	GVCF_LIST=$(mktemp)
	DXGVCF_LIST=$(mktemp)
	
	cd $WKDIR
	
	for i in "${!vcfidx_files[@]}"; do	
		dx download "${vcfidx_files[$i]}"
	done
	
	for i in "${!vcf_files[@]}"; do
		echo "${vcf_files[$i]}" >> $DXGVCF_LIST
	done
	
	# Now, download and index in parallel, please
	parallel -u -j $(nproc --all) --gnu dl_index :::: $DXGVCF_LIST ::: $WKDIR ::: $GVCF_LIST
		
	# get the resources we need in /usr/share/GATK
	sudo mkdir -p /usr/share/GATK/resources
	sudo chmod -R a+rwX /usr/share/GATK
		
	dx download $(dx find data --name "GenomeAnalysisTK-3.2-2.jar" --project $DX_RESOURCES_ID --brief) -o /usr/share/GATK/GenomeAnalysisTK-3.2-2.jar
	dx download $(dx find data --name "dbsnp_137.b37.vcf.gz" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/dbsnp_137.b37.vcf.gz
	dx download $(dx find data --name "dbsnp_137.b37.vcf.gz.tbi" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/dbsnp_137.b37.vcf.gz.tbi
	dx download $(dx find data --name "human_g1k_v37_decoy.fasta" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.fasta
	dx download $(dx find data --name "human_g1k_v37_decoy.fasta.fai" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.fasta.fai
	dx download $(dx find data --name "human_g1k_v37_decoy.dict" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.dict
	
    TOT_MEM=$(free -m | grep "Mem" | awk '{print $2}')
    # only ask for 90% of total system memory
    TOT_MEM=$((TOT_MEM * 9 / 10))
	VCF_TMPDIR=$(mktemp -d)
	# OK, now we can call the GATK genotypeGVCFs
	java -d64 -Xms512m -Xmx${TOT_MEM}m -jar /usr/share/GATK/GenomeAnalysisTK-3.2-2.jar \
	-T GenotypeGVCFs \
	-A QualByDepth \
	-A HaplotypeScore \
	-A MappingQualityRankSumTest \
	-A ReadPosRankSumTest \
	-A FisherStrand \
	-A GCContent \
	-A AlleleBalance \
	-A InbreedingCoeff \
	-A StrandOddsRatio \
	-A GenotypeSummaries $ADDL_CMD \
	-nt $(nproc --all) \
	-R /usr/share/GATK/resources/human_g1k_v37_decoy.fasta \
	$(cat $GVCF_LIST | sed "s|^|-V |" | tr '\n' ' ') \
	--dbsnp /usr/share/GATK/resources/dbsnp_137.b37.vcf.gz \
	-o "$VCF_TMPDIR/$PREFIX.vcf.gz"
	
	
    # The following line(s) use the dx command-line tool to upload your file
    # outputs after you have created them on the local file system.  It assumes
    # that you have used the output field name for the filename for each output,
    # but you can change that behavior to suit your needs.  Run "dx upload -h"
    # to see more options to set metadata.

	vcf_fn=$(dx upload "$VCF_TMPDIR/$PREFIX.vcf.gz" --brief)
    vcf_idx_fn=$(dx upload "$VCF_TMPDIR/$PREFIX.vcf.gz.tbi" --brief)

    # The following line(s) use the utility dx-jobutil-add-output to format and
    # add output variables to your job's output as appropriate for the output
    # class.  Run "dx-jobutil-add-output -h" for more information on what it
    # does.

    dx-jobutil-add-output vcf_out "$vcf_fn" --class=file
    dx-jobutil-add-output vcfidx_out "$vcf_idx_fn" --class=file
}

merge_vcf() {
	# set the shell to work w/ GNU parallel
	export SHELL="/bin/bash"
	
	if test -z "$PREFIX"; then
		PREFIX="combined"
	fi

	WKDIR=$(mktemp -d)
	GVCF_LIST=$(mktemp)
	DXGVCF_LIST=$(mktemp)
	
	cd $WKDIR
	
	for i in "${!vcfidx_files[@]}"; do	
		dx download "${vcfidx_files[$i]}"
	done
	
	for i in "${!vcf_files[@]}"; do
		echo "${vcf_files[$i]}" >> $DXGVCF_LIST
	done
			
	# get the resources we need in /usr/share/GATK
	sudo mkdir -p /usr/share/GATK/resources
	sudo chmod -R a+rwX /usr/share/GATK
		
	dx download $(dx find data --name "GenomeAnalysisTK-3.3-0.jar" --project $DX_RESOURCES_ID --brief) -o /usr/share/GATK/GenomeAnalysisTK-3.3-0.jar
	dx download $(dx find data --name "human_g1k_v37_decoy.fasta" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.fasta
	dx download $(dx find data --name "human_g1k_v37_decoy.fasta.fai" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.fasta.fai
	dx download $(dx find data --name "human_g1k_v37_decoy.dict" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.dict
		
	# download the already split VCFs
	GVCF_LIST=$(mktemp)
	parallel -u -j $(nproc --all) --gnu dl_index :::: $DXGVCF_LIST ::: $WKDIR ::: $GVCF_LIST
	
	FINAL_DIR=$(mktemp -d)
	TOT_MEM=$(free -m | grep "Mem" | awk '{print $2}')
	java -d64 -Xms512m -Xmx$((TOT_MEM * 9 / 10))m -jar /usr/share/GATK/GenomeAnalysisTK-3.3-0.jar \
	-T CombineVariants -nt $(nproc --all) --assumeIdenticalSamples \
	-R /usr/share/GATK/resources/human_g1k_v37_decoy.fasta \
	$(ls -1 $WKDIR/*.vcf.gz | sed 's/^/-V /' | tr '\n' ' ') \
	-genotypeMergeOptions UNSORTED \
	-o $FINAL_DIR/$PREFIX.vcf.gz
				
	VCF_DXFN=$(dx upload ${FINAL_DIR}/$PREFIX.vcf.gz --brief)
	VCFIDX_DXFN=$(dx upload ${FINAL_DIR}/$PREFIX.vcf.gz.tbi --brief)
		
	# and upload it and we're done!
	dx-jobutil-add-output vcf_out "$VCF_DXFN" --class=file
	dx-jobutil-add-output vcfidx_out "$VCFIDX_DXFN" --class=file
}
