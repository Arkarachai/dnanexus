#!/bin/bash
# geno_p 0.0.1
# Generated by dx-app-wizard.
#
# Parallelized execution pattern: Your app will generate multiple jobs
# to perform some computation in parallel, followed by a final
# "postprocess" stage that will perform any additional computations as
# necessary.
#
# Your job's input variables (if any) will be loaded as environment
# variables before this script runs.  Any array inputs will be loaded
# as bash arrays.
#
# Any code outside of main() or any other entry point is ALWAYS
# executed, followed by running the entry point itself.
#
# See https://wiki.dnanexus.com/Developer-Portal for tutorials on how
# to modify this file.

set -x

# install GNU parallel!
sudo sed -i 's/^# *\(deb .*backports.*\)$/\1/' /etc/apt/sources.list
sudo apt-get update
sudo apt-get install --yes parallel

sudo pip install pytabix

function parallel_download() {
	set -x
	cd $2
	dx download "$1"
	cd -
}
export -f parallel_download

function dl_part_index() {
	set -x
	echo "'$1', '$2', '$3', '$4'"
	cd "$2"
	fn=$(dx describe --name "$1")
	fn_base=$(echo "$fn" | sed 's/.vcf.gz$//')
	file_url=$(dx make_download_url "$1")
	file_dxid=$(dx describe --json "$1" | jq .id | sed 's/\"//g')
	idxfn=$(ls "$2/$fn.tbi")
	
	set -o 'pipefail'
	
	RERUN=1
	MAX_RETRY=5
	while test $RERUN -ne 0 -a $MAX_RETRY -gt 0; do
		download_part.py -f "$file_dxid" -i "$idxfn" -L "$3" -o "$4/$fn_base.$3.vcf.gz" -H
		RERUN="$?"
		MAX_RETRY=$((MAX_RETRY - 1))
	done
	
	# Make sure to cause problems downstream if we didn't succeed
	if test "$RERUN" -eq 0; then
		tabix -p vcf "$4/$fn_base.$3.vcf.gz"
	fi
}

export -f dl_part_index

function dl_index() {
 	set -x
	echo "'$1', '$2', '$3'"
 	cd "$2"
 	fn=$(dx describe --name "$1")
	dx download "$1" -o "$fn"
	if test -z "$(ls $fn.tbi)"; then
		tabix -p vcf $fn
	fi
	echo "$2/$fn" >> $3
}

export -f dl_index


main() {

	export SHELL="/bin/bash"
	ADDL_CMD=""

	PADDED=0

	SUBJOB_ARGS=""
	if test "$target_file"; then
		tgt_id=$(dx describe "$target_file" --json | jq .id | sed 's/"//g')
		SUBJOB_ARGS="$SUBJOB_ARGS -itarget_file:file=$tgt_id"
		
		if [ -n "$padding" ] && [ "$padding" -ne 0 ] ; then 
			SUBJOB_ARGS="$SUBJOB_ARGS -ipadding:int=$padding"
			PADDED=1
		fi
	fi
	
	if test -z "$PREFIX"; then
		PREFIX="combined"
	fi
	
	WKDIR=$(mktemp -d)
	GVCF_SPLITDIR=$(mktemp -d)
	DXGVCF_LIST=$(mktemp)
	DXGVCFIDX_LIST=$(mktemp)
	
	cd $WKDIR
	
	# Get a list of chromosomes
	dx download "${gvcfidxs[0]}" -o test.vcf.gz.tbi
	CHROM_LIST=$(mktemp)
	tabix -l test.vcf.gz > $CHROM_LIST
	
	
	for i in "${!gvcfidxs[@]}"; do	
		echo "${gvcfidxs[$i]}" >> $DXGVCFIDX_LIST
	done
	
	for i in "${!gvcfs[@]}"; do
		echo "${gvcfs[$i]}" >> $DXGVCF_LIST
	done
	
	GVCF_LIST=$(dx upload $DXGVCF_LIST --brief)
	GVCFIDX_LIST=$(dx upload $DXGVCFIDX_LIST --brief)
	
	# Kick off each of those subjobs
	CIDX=0
	pparg=""
	pp_pad_arg=""
	while read chrom; do
		process_jobs[$CIDX]=$(dx-jobutil-new-job genotype_gvcfs -iPREFIX=$PREFIX.$chrom -ichrom=$chrom -ivcf_files:file="$GVCF_LIST" -ivcfidx_files:file="$GVCFIDX_LIST" $SUBJOB_ARGS)
		pparg="$pparg -ivcf_files=${process_jobs[$CIDX]}:vcf_out -ivcfidx_files=${process_jobs[$CIDX]}:vcfidx_out -ivcf_hdr_files=${process_jobs[$CIDX]}:vcf_hdr_out -ivcfidx_hdr_files=${process_jobs[$CIDX]}:vcfidx_hdr_out"
		pp_pad_arg="$pp_pad_arg -ivcf_files=${process_jobs[$CIDX]}:vcf_pad_out -ivcfidx_files=${process_jobs[$CIDX]}:vcfidx_pad_out -ivcf_hdr_files=${process_jobs[$CIDX]}:vcf_pad_hdr_out -ivcfidx_pad_hdr_files=${process_jobs[$CIDX]}:vcfidx_hdr_out"
		CIDX=$((CIDX + 1))
	done < $CHROM_LIST
	
	# OK, now we simply have to merge all of the VCF files together
	postprocess=$(dx-jobutil-new-job merge_vcf $pparg -iPREFIX:string="$PREFIX" --depends-on ${process_jobs[@]})
	dx-jobutil-add-output vcf "$postprocess:vcf_out" --class=jobref
	dx-jobutil-add-output vcfidx "$postprocess:vcfidx_out" --class=jobref
    dx-jobutil-add-output vcf_header "$postprocess:vcf_hdr_out" --class=jobref
    dx-jobutil-add-output vcfidx_header "$postprocess:vcfidx_hdr_out" --class=jobref
    
    if test "$PADDED" -ne 0; then
    	postprocess_pad=$(dx-jobutil-new-job merge_vcf $pp_pad_arg -iPREFIX:string="$PREFIX.padded" --depends-on ${process_jobs[@]})
		dx-jobutil-add-output vcf_pad "$postprocess_pad:vcf_out" --class=jobref
		dx-jobutil-add-output vcfidx_pad "$postprocess_pad:vcfidx_out" --class=jobref
    	dx-jobutil-add-output vcf_pad_header "$postprocess_pad:vcf_hdr_out" --class=jobref
    	dx-jobutil-add-output vcfidx_pad_header "$postprocess_pad:vcfidx_hdr_out" --class=jobref
    else
		dx-jobutil-add-output vcf_pad "$postprocess:vcf_out" --class=jobref
		dx-jobutil-add-output vcfidx_pad "$postprocess:vcfidx_out" --class=jobref
    	dx-jobutil-add-output vcf_pad_header "$postprocess:vcf_hdr_out" --class=jobref
    	dx-jobutil-add-output vcfidx_pad_header "$postprocess:vcfidx_hdr_out" --class=jobref
    fi
    	
}

genotype_gvcfs() {

	export SHELL="/bin/bash"
	ADDL_CMD=""
	
	PADDED=0

	if test "$target_file"; then
		dx download "$target_file" -o targets_raw.bed
		sed -n "/^$chrom[ \t].*/p" targets_raw.bed > targets.bed
		if test "$padding"; then
			cat targets.bed | interval_pad.py $padding | tr ' ' '\t' | sort -n -k2,3 > targets.padded.bed
			ADDL_CMD="-L $PWD/targets.padded.bed"
			PADDED=1
		else
			ADDL_CMD="-L $PWD/targets.bed"
		fi

	else
		ADDL_CMD="-L $chrom"
	fi
	
	if test -z "$PREFIX"; then
		PREFIX="combined"
	fi
	
	WKDIR=$(mktemp -d)
	OUTDIR=$(mktemp -d)
	GVCF_LIST=$(mktemp)
	DXGVCF_LIST=$(mktemp)
	DXGVCFIDX_LIST=$(mktemp)
	
	cd $WKDIR
	
	dx download "${vcfidx_files}" -f -o $DXGVCFIDX_LIST
	parallel -u -j $(nproc --all) --gnu parallel_download :::: $DXGVCFIDX_LIST ::: $WKDIR
	
	dx download "${vcf_files}" -f -o $DXGVCF_LIST
	
	# Now, download and index in parallel, please
	parallel -u -j $(nproc --all) --gnu dl_part_index :::: $DXGVCF_LIST ::: $WKDIR ::: $chrom ::: $OUTDIR
	
	echo "Contents of WKDIR:"
	ls -alh $WKDIR
	
	echo "Contents of OUTDIR:"
	ls -alh $OUTDIR
	
	sleep 10	
		
	# get the resources we need in /usr/share/GATK
	sudo mkdir -p /usr/share/GATK/resources
	sudo chmod -R a+rwX /usr/share/GATK
		
	dx download $(dx find data --name "GenomeAnalysisTK-3.2-2.jar" --project $DX_RESOURCES_ID --brief) -o /usr/share/GATK/GenomeAnalysisTK-3.2-2.jar
	dx download $(dx find data --name "GenomeAnalysisTK-3.3-0-custom.jar" --project $DX_RESOURCES_ID --brief) -o /usr/share/GATK/GenomeAnalysisTK-3.3-0-custom.jar
	dx download $(dx find data --name "dbsnp_137.b37.vcf.gz" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/dbsnp_137.b37.vcf.gz
	dx download $(dx find data --name "dbsnp_137.b37.vcf.gz.tbi" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/dbsnp_137.b37.vcf.gz.tbi
	dx download $(dx find data --name "human_g1k_v37_decoy.fasta" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.fasta
	dx download $(dx find data --name "human_g1k_v37_decoy.fasta.fai" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.fasta.fai
	dx download $(dx find data --name "human_g1k_v37_decoy.dict" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.dict
	
    TOT_MEM=$(free -m | grep "Mem" | awk '{print $2}')
    # only ask for 90% of total system memory
    TOT_MEM=$((TOT_MEM * 9 / 10))
	VCF_TMPDIR=$(mktemp -d)
	# OK, now we can call the GATK genotypeGVCFs
	java -d64 -Xms512m -Xmx${TOT_MEM}m -jar /usr/share/GATK/GenomeAnalysisTK-3.2-2.jar \
	-T GenotypeGVCFs \
	-A QualByDepth \
	-A HaplotypeScore \
	-A MappingQualityRankSumTest \
	-A ReadPosRankSumTest \
	-A FisherStrand \
	-A GCContent \
	-A AlleleBalance \
	-A InbreedingCoeff \
	-A StrandOddsRatio \
	-A HardyWeinberg \
	-A ChromosomeCounts \
	-A VariantType \
	-A GenotypeSummaries $ADDL_CMD \
	-nt $(nproc --all) \
	-R /usr/share/GATK/resources/human_g1k_v37_decoy.fasta \
	$(ls $OUTDIR/*.vcf.gz | sed 's/^/-V /' | tr '\n' ' ') \
	--dbsnp /usr/share/GATK/resources/dbsnp_137.b37.vcf.gz \
	-o "$VCF_TMPDIR/$PREFIX.vcf.gz"
	  
    # Now, if we padded the intervals, get an on-target VCF through the use of SelectVariants
    if test "$PADDED" -ne 0; then
    	mv "$VCF_TMPDIR/$PREFIX.vcf.gz" "$VCF_TMPDIR/$PREFIX.padded.vcf.gz"
    	mv "$VCF_TMPDIR/$PREFIX.vcf.gz.tbi" "$VCF_TMPDIR/$PREFIX.padded.vcf.gz.tbi"
    
    	java -d64 -Xms512m -Xmx${TOT_MEM}m -jar /usr/share/GATK/GenomeAnalysisTK-3.3-0-custom.jar \
			-T SelectVariants $(echo $ADDL_CMD | sed 's|^\(.*\)/[^/]*$|\1/targets.bed|') \
			-R /usr/share/GATK/resources/human_g1k_v37_decoy.fasta \
			-nt $(nproc --all) \
			-V "$VCF_TMPDIR/$PREFIX.padded.vcf.gz" \
			-o "$VCF_TMPDIR/$PREFIX.vcf.gz" 
			
		# get only the 1st 8 (summary) columns - will be helpful when running VQSR or other variant-level information
		pigz -dc "$VCF_TMPDIR/$PREFIX.padded.vcf.gz" | cut -f1-8 | bgzip -c > "$VCF_TMPDIR/$PREFIX.padded.header.vcf.gz"
		tabix -p vcf "$VCF_TMPDIR/$PREFIX.padded.header.vcf.gz"
		
		# upload all of the padded files
		
		vcf_pad_fn=$(dx upload "$VCF_TMPDIR/$PREFIX.padded.vcf.gz" --brief)
	    vcf_idx_pad_fn=$(dx upload "$VCF_TMPDIR/$PREFIX.padded.vcf.gz.tbi" --brief)

		dx-jobutil-add-output vcf_pad_out "$vcf_pad_fn" --class=file
		dx-jobutil-add-output vcfidx_pad_out "$vcf_idx_pad_fn" --class=file
		
	   	vcf_pad_hdr_fn=$(dx upload "$VCF_TMPDIR/$PREFIX.padded.header.vcf.gz" --brief)
		vcf_idx_pad_hdr_fn=$(dx upload "$VCF_TMPDIR/$PREFIX.padded.header.vcf.gz.tbi" --brief)

		dx-jobutil-add-output vcf_pad_hdr_out "$vcf_pad_hdr_fn" --class=file
		dx-jobutil-add-output vcfidx_pad_hdr_out "$vcf_idx_pad_hdr_fn" --class=file
	fi
	  	
   	# get only the 1st 8 (summary) columns - will be helpful when running VQSR or other variant-level information
	pigz -dc "$VCF_TMPDIR/$PREFIX.vcf.gz" | cut -f1-8 | bgzip -c > "$VCF_TMPDIR/$PREFIX.header.vcf.gz"
	tabix -p vcf "$VCF_TMPDIR/$PREFIX.header.vcf.gz"	
	
	vcf_fn=$(dx upload "$VCF_TMPDIR/$PREFIX.vcf.gz" --brief)
    vcf_idx_fn=$(dx upload "$VCF_TMPDIR/$PREFIX.vcf.gz.tbi" --brief)

    dx-jobutil-add-output vcf_out "$vcf_fn" --class=file
    dx-jobutil-add-output vcfidx_out "$vcf_idx_fn" --class=file
    
   	vcf_hdr_fn=$(dx upload "$VCF_TMPDIR/$PREFIX.header.vcf.gz" --brief)
    vcf_idx_hdr_fn=$(dx upload "$VCF_TMPDIR/$PREFIX.header.vcf.gz.tbi" --brief)

    dx-jobutil-add-output vcf_hdr_out "$vcf_hdr_fn" --class=file
    dx-jobutil-add-output vcfidx_hdr_out "$vcf_idx_hdr_fn" --class=file


}

merge_vcf() {
	# set the shell to work w/ GNU parallel
	export SHELL="/bin/bash"
	
	if test -z "$PREFIX"; then
		PREFIX="combined"
	fi

	WKDIR=$(mktemp -d)
	HDR_WKDIR=$(mktemp -d)
	GVCF_LIST=$(mktemp)
	DXGVCF_LIST=$(mktemp)
	DXGCVFIDX_LIST=$(mktemp)
	GVCF_HDR_LIST=$(mktemp)
	DXGVCF_HDR_LIST=$(mktemp)
	DXGCVFIDX_HDR_LIST=$(mktemp)


	for i in "${!vcfidx_files[@]}"; do	
		echo "${vcfidx_files[$i]}" >> $DXGCVFIDX_LIST
	done
	for i in "${!vcf_files[@]}"; do
		echo "${vcf_files[$i]}" >> $DXGVCF_LIST
	done
	
	parallel -u --gnu -j $(nproc --all) parallel_download :::: $DXGCVFIDX_LIST ::: $WKDIR
	# download the already split VCFs
	parallel -u -j $(nproc --all) --gnu dl_index :::: $DXGVCF_LIST ::: $WKDIR ::: $GVCF_LIST

	for i in "${!vcfidx_hdr_files[@]}"; do	
		echo "${vcfidx_hdr_files[$i]}" >> $DXGCVFIDX_HDR_LIST
	done
	for i in "${!vcf_hdr_files[@]}"; do
		echo "${vcf_hdr_files[$i]}" >> $DXGVCF_HDR_LIST
	done
	
	parallel -u --gnu -j $(nproc --all) parallel_download :::: $DXGCVFIDX_HDR_LIST ::: $HDR_WKDIR
	# download the already split VCFs
	parallel -u -j $(nproc --all) --gnu dl_index :::: $DXGVCF_HDR_LIST ::: $HDR_WKDIR ::: $GVCF_HDR_LIST
	
			
	# get the resources we need in /usr/share/GATK
	sudo mkdir -p /usr/share/GATK/resources
	sudo chmod -R a+rwX /usr/share/GATK
		
	dx download $(dx find data --name "GenomeAnalysisTK-3.3-0.jar" --project $DX_RESOURCES_ID --brief) -o /usr/share/GATK/GenomeAnalysisTK-3.3-0.jar
	dx download $(dx find data --name "human_g1k_v37_decoy.fasta" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.fasta
	dx download $(dx find data --name "human_g1k_v37_decoy.fasta.fai" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.fasta.fai
	dx download $(dx find data --name "human_g1k_v37_decoy.dict" --project $DX_RESOURCES_ID --folder /resources --brief) -o /usr/share/GATK/resources/human_g1k_v37_decoy.dict
		
	cd $WKDIR
	
	FINAL_DIR=$(mktemp -d)
	TOT_MEM=$(free -m | grep "Mem" | awk '{print $2}')
	java -d64 -Xms512m -Xmx$((TOT_MEM * 9 / 10))m -jar /usr/share/GATK/GenomeAnalysisTK-3.3-0.jar \
	-T CombineVariants -nt $(nproc --all) --assumeIdenticalSamples \
	-R /usr/share/GATK/resources/human_g1k_v37_decoy.fasta \
	$(ls -1 $WKDIR/*.vcf.gz | sed 's/^/-V /' | tr '\n' ' ') \
	-genotypeMergeOptions UNSORTED \
	-o $FINAL_DIR/$PREFIX.vcf.gz

	VCF_DXFN=$(dx upload ${FINAL_DIR}/$PREFIX.vcf.gz --brief)
	VCFIDX_DXFN=$(dx upload ${FINAL_DIR}/$PREFIX.vcf.gz.tbi --brief)
		
	# and upload it and we're done!
	dx-jobutil-add-output vcf_out "$VCF_DXFN" --class=file
	dx-jobutil-add-output vcfidx_out "$VCFIDX_DXFN" --class=file

	java -d64 -Xms512m -Xmx$((TOT_MEM * 9 / 10))m -jar /usr/share/GATK/GenomeAnalysisTK-3.3-0.jar \
	-T CombineVariants -nt $(nproc --all) --assumeIdenticalSamples \
	-R /usr/share/GATK/resources/human_g1k_v37_decoy.fasta \
	$(ls -1 $HDR_WKDIR/*.vcf.gz | sed 's/^/-V /' | tr '\n' ' ') \
	-genotypeMergeOptions UNSORTED \
	-o $FINAL_DIR/$PREFIX.header.vcf.gz
	
	VCF_HDR_DXFN=$(dx upload ${FINAL_DIR}/$PREFIX.header.vcf.gz --brief)
	VCFIDX_HDR_DXFN=$(dx upload ${FINAL_DIR}/$PREFIX.header.vcf.gz.tbi --brief)
		
	# and upload it and we're done!
	dx-jobutil-add-output vcf_hdr_out "$VCF_HDR_DXFN" --class=file
	dx-jobutil-add-output vcfidx_hdr_out "$VCFIDX_HDR_DXFN" --class=file

		
}
