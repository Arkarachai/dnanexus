#!/bin/bash
# rvtest_single_vcf 0.0.1
# Generated by dx-app-wizard.
#
# Parallelized execution pattern: Your app will generate multiple jobs
# to perform some computation in parallel, followed by a final
# "postprocess" stage that will perform any additional computations as
# necessary.
#
# Your job's input variables (if any) will be loaded as environment
# variables before this script runs.  Any array inputs will be loaded
# as bash arrays.
#
# Any code outside of main() or any other entry point is ALWAYS
# executed, followed by running the entry point itself.
#
# See https://wiki.dnanexus.com/Developer-Portal for tutorials on how
# to modify this file.

set -x 

main() {

    echo "Value of vcf_files: '${vcf_files[@]}'"
    echo "Value of pheno_files: '${pheno_files[@]}'"
    echo "Value of kinship_file: '$kinship_file'"
    echo "Value of gen_score: '$gen_score'"
    echo "Value of gen_cov: '$gen_cov'"
    echo "Value of prefix: '$prefix'"
    echo "Value of split_instance: '$split_instance'"
    echo "Value of rvtest_instance: '$rvtest_instance'"
    echo "Value of merge_instance: '$merge_instance'"

    # find smallest vcf file to test
    min=20000
    checkvcf="${vcf_files[0]}"
    for file in "${vcf_files[@]}"
    do
      file_size=$(dx ls --verbose "$file" |awk '{print $4}')
      comparison=$(echo "$file_size < $min"|bc -l)
      if(( "$comparison" > 0)) ; then
        min=$file_size
        checkvcf=$file
      fi
    done

     id_error=0

     dx download "$checkvcf" -o idcheck.vcf.gz

     # check each phenotype against the smallest VCF file for ID matching
     for phenofile in "${pheno_files[@]}"
     do
       dx download "$phenofile" -o pheno.ped -f
       matches=$(zcat idcheck.vcf.gz| grep 'CHROM' |tr '\t' '\n' |grep -Fwf <(cat pheno.ped| awk '{print $2}') |wc -l)  
       if(( matches == 0 )) ; then
         pheno_orig=$(dx describe "$phenofile" --name) 
         vcf_orig=$(dx describe "$checkvcf" --name)
        echo "Problem with phenotype and VCF IDs.  No matches for $pheno_orig and $vcf_orig." 
        id_error=1
       fi
       phenoid=$(parse_link.pl "$phenofile")
       pheno_file_input="$pheno_file_input -ipheno_files:array:string=$phenoid "
     done
    
   if(( "$id_error" == 1 )) ; then
     exit 1
   fi

    for i in ${!vcf_files[@]}
    do
       filename=$(dx describe "${vcf_files[$i]}" --name)
       # get basename of the vcf input file
       if [[ "$filename" =~ (.+)(.vcf.gz)$ ]] ; then
         basename="${BASH_REMATCH[1]}"
       else
         basename="${vcf_files[$i]}"
       fi
       # add prefix 
       if [ -n "$prefix" ] ; then
         newprefix="${prefix}_$basename"
       else
         newprefix="$basename"
       fi 

       if [ -n "$kinship_file" ] ; then
#         jobid=$(dx-jobutil-new-job runvcf -ivcf_file="${vcf_files[$i]}" -ikinship_file="$kinship_file" -ipheno_files="${pheno_files[@]}" -igen_score=$gen_score -igen_cov=$gen_cov -iprefix="$newprefix" -irvtest_instance=$rvtest_instance -imerge_instance=$merge_instance --instance-type $split_instance)         
          jobid=$(dx-jobutil-new-job runvcf -ivcf_file="${vcf_files[$i]}" -ikinship_file="$kinship_file" $pheno_file_input -igen_score=$gen_score -igen_cov=$gen_cov -iprefix="$newprefix" -irvtest_instance=$rvtest_instance -imerge_instance=$merge_instance --instance-type $split_instance)
       else
#         jobid=$(dx-jobutil-new-job runvcf -ivcf_file="${vcf_files[$i]}" -ipheno_files="${pheno_files[@]}" -igen_score=$gen_score -igen_cov=$gen_cov -iprefix="$newprefix" -irvtest_instance=$rvtest_instance -imerge_instance=$merge_instance --instance-type $split_instance)
         jobid=$(dx-jobutil-new-job runvcf -ivcf_file="${vcf_files[$i]}" $pheno_file_input -igen_score=$gen_score -igen_cov=$gen_cov -iprefix="$newprefix" -irvtest_instance=$rvtest_instance -imerge_instance=$merge_instance --instance-type $split_instance)
       fi
       dx-jobutil-add-output out "$jobid:output_files" --class=array:jobref 
    done

}

runvcf() {

    echo "Value of vcf_file: '$vcf_file'"
    echo "Value of pheno_files: '${pheno_files[@]}'"
    echo "Value of kinship_file: '$kinship_file'"
    echo "Value of gen_score: '$gen_score'"
    echo "Value of gen_cov: '$gen_cov'"
    echo "Value of prefix: '$prefix'"
    echo "Value of rvtest_instance: '$rvtest_instance'"
    echo "Value of merge_instance: '$merge_instance'"

    # The following line(s) use the dx command-line tool to download your file
    # inputs to the local file system using variable names for the filenames. To
    # recover the original filenames, you can use the output of "dx describe
    # "$variable" --name".

    for i in "${!pheno_files[@]}"
    do
      pheno_files[$i]=$(dx-jobutil-dxlink "${pheno_files[$i]}")
    done

    dx download "$vcf_file" -o file.vcf.gz

    #dx download "$pheno_file" -o pheno_file
    process_args=""
    if [ -n "$kinship_file" ]
    then
        process_args="-ikinship_file=\"$kinship_file\" "
    fi

    # create plan for splitting VCF file
    python /usr/bin/SplitVCFwithShadow_makePlan.py \
    --Input=file.vcf.gz \
    --Output=split.plan \
    --RoughChunkSize=100000 --WindowSizeBps=500000

    # split the VCF into sections for running independently
    python /usr/bin/SplitVCFwithShadow_SplitAsPlanned.py \
    --Input=file.vcf.gz \
    --Output=rvtests.input.vcf.*.gz \
    --Plan=split.plan

    shopt -s nullglob
    rvtests_in=(rvtests.input.vcf.*.gz)

    # To report any recognized errors in the correct format in
    # $HOME/job_error.json and exit this script, you can use the
    # dx-jobutil-report-error utility as follows:
    #
    #   dx-jobutil-report-error "My error message"
    #
    # Note however that this entire bash script is executed with -e
    # when running in the cloud, so any line which returns a nonzero
    # exit code will prematurely exit the script; if no error was
    # reported in the job_error.json file, then the failure reason
    # will be AppInternalError with a generic error message.
    #
    # Split your work into parallel tasks.  As an example, the
    # following generates 10 subjobs running with the same dummy
    # input.  The utility dx-jobutil-new-job uses the same syntax as
    # dx run for specifying input, and you can explicitly specify the
    # class to enable proper parsing.

    planfile=$(dx upload --brief split.plan)
    planfile="{\"\$dnanexus_link\": \"$planfile\"}"
    orig_prefix=$prefix

    for j in "${!pheno_files[@]}"
    do
      pheno_file="${pheno_files[$j]}"
      original_pheno=$(dx describe "$pheno_file" --name)
      prefix="${original_pheno}_$orig_prefix"

      postprocess_args=""
      for i in "${!rvtests_in[@]}"
      do
          filenum=1
          if [[ "${rvtests_in[$i]}" =~ ([0-9]+)(.gz)$ ]]         
          then
            filenum=${BASH_REMATCH[1]}
          fi
          echo "filenum = $filenum for ${rvtests_in[$i]}"
          vcfout=$(dx upload --brief "${rvtests_in[$i]}")
          vcfout="{\"\$dnanexus_link\": \"$vcfout\"}"
          echo "vcfout=$vcfout"

         if [ -n "$kinship_file" ]
         then
           process_jobs[$i]=$(dx-jobutil-new-job process -ikinship_file="$kinship_file" -ipfile="$pheno_file" -igscore=$gen_score -igcov=$gen_cov -ivcf="$vcfout" -ifnum=$filenum --instance-type $rvtest_instance)
         else
           process_jobs[$i]=$(dx-jobutil-new-job process -ipfile="$pheno_file" -igscore=$gen_score -igcov=$gen_cov -ivcf="$vcfout" -ifnum=$filenum --instance-type $rvtest_instance)
         fi


         if [ "$gen_score" == true ] ; then
           postprocess_args="$postprocess_args -iscore_files=${process_jobs[$i]}:score_files "
         fi
         if [ "$gen_cov" == true ] ; then
           postprocess_args="$postprocess_args -icov_files=${process_jobs[$i]}:cov_files "
         fi
      done

    # The following line creates the postprocess job that will only
    # run after all of the "process" subjobs are done.
      postprocess=$(dx-jobutil-new-job postprocess -iprefix=$prefix -iplanfile="$planfile" $postprocess_args --depends-on ${process_jobs[@]} --instance-type $merge_instance)

      dx-jobutil-add-output output_files "$postprocess:output_files" --class=array:jobref
    done

    # The following line(s) use the dx command-line tool to upload your file
    # outputs after you have created them on the local file system.  It assumes
    # that you have used the output field name for the filename for each output,
    # but you can change that behavior to suit your needs.  Run "dx upload -h"
    # to see more options to set metadata.


    # If you would like to include any of the output fields from the
    # postprocess job as the output of your app, you should return it
    # here using a reference.  If the output field in the postprocess
    # function is called "answer", you can set that in the output hash
    # as follows.
    #
    #   dx-jobutil-add-output app_output_field "$postprocess":answer --class=jobref
    #
    # Tip: you can include in your output at this point any open
    # objects (such as gtables) which are closed by another entry
    # point that finishes later.  The system will check to make sure
    # that the output object is closed and will attempt to clone it
    # out as output into the parent container only after all subjobs
    # have finished.

    # The following line(s) use the utility dx-jobutil-add-output to format and
    # add output variables to your job's output as appropriate for the output
    # class.  Run "dx-jobutil-add-output -h" for more information on what it
    # does.
}

process() {
    # Fill in your process code here
    echo "Value of process vcf = '$vcf'"
    echo "Value of process pfile = '$pfile'"
    echo "Value of process phname = '$phname'"
    echo "Value of kinship_file: '$kinship_file'"
    echo "Value of fnum: '$fnum'"
    echo "Value of gscore: '$gscore'"
    echo "Value of gcov: '$gcov'"
    INPUTIDR=$(mktemp -d)
    OUTPUTDIR=$(mktemp -d)
    cd $INPUTDIR
    dx download "$pfile" -o input_pheno_file
    dx download "$vcf" -o input.vcf.gz
    options="$options --inVcf input.vcf.gz --pheno input_pheno_file --mpheno 1 "
    if [ -n "$kinship_file" ]
    then
      dx download "$kinship_file" -o input_kinship_file
      options="$options --kinship input_kinship_file " 
    fi
    if [ "$gscore"==true ] && [ "$gcov"==true ] ; then
      options="$options --meta score,cov[windowSize=500000] "
    elif [ "$gscore"==true ] ; then
      options="$options --meta score "
    elif [ "$gcov"==true ] ; then
      options="$options --meta cov[windowSize=500000] "
    fi
    options="$options --dosage DS "
  
    outputfn="$OUTPUTDIR/test_output_$fnum"
    options="$options --out $outputfn"
    echo rvtest "$options"
    rvtest $options --noweb

    cd $OUTPUTDIR

    shopt -s nullglob
    scfiles=(*.MetaScore.assoc.gz)
    covfiles=(*.MetaCov.assoc.gz)
    if(( ${#scfiles[@]} > 0 ))
    then
      echo "dx uploading ${scfiles[0]}"
      scfile=$(dx upload --brief ${scfiles[0]})
      dx-jobutil-add-output score_files "$scfile" --class=file
    fi
    if(( ${#covfiles[@]} > 0 ))
    then
      echo "dx uploading ${covfiles[0]}"
      covfile=$(dx upload --brief ${covfiles[0]})
      dx-jobutil-add-output cov_files "$covfile" --class=file
    fi 
}

postprocess() {
    # Fill in your postprocess code here
   echo "Value of postprocess prefix: '${prefix}'"
   
   if [ -n "$score_files" ] ; then
   for i in "${score_files[@]}"
   do
     echo "Value of score_files element: '$i'"
     out_name=$(dx describe "$i" --name)
     dx download "$i" -o $out_name
   done
   fi

   if [ -n "$cov_files" ] ; then
   for i in "${cov_files[@]}"
   do
     echo "Value of cov_files element: '$i'"
     out_name=$(dx describe "$i" --name)
     dx download "$i" -o $out_name
   done
   fi



   shopt -s nullglob
   scorefiles=(*.MetaScore.assoc.gz)
   covfiles=(*.MetaCov.assoc.gz)

   echo "Value of planfile:  '$planfile' "
   dx download "$planfile" -o planfile

   ls
   if(( ${#scorefiles[@]} > 0 ))
   then
     echo "processing score files"
   # Combine the MetaScore files according to the plan generated in main
     echo " python /usr/bin/CombineRvtestsScoreOrCov_CombineAsPlaned.py --Input=test_output_*.MetaScore.assoc.gz --Output=combined.mScore.assoc.gz --Plan=planfile"
     python /usr/bin/CombineRvtestsScoreOrCov_CombineAsPlaned.py --Output=combined.mScore.assoc.gz --Plan=planfile "--Input=test_output_*.MetaScore.assoc.gz"
     zcat combined.mScore.assoc.gz | bgzip > "${prefix}.MetaScore.assoc.gz"
     rm combined.mScore.assoc.gz
     metascorefn=$(dx upload --brief "${prefix}.MetaScore.assoc.gz" )      
     dx-jobutil-add-output output_files "${metascorefn}" --class=array:file
   fi

   if(( ${#covfiles[@]} > 0 ))
   then
     echo "processing cov files"
   # Combine the MetaCov files according to the plan generated in main
     python /usr/bin/CombineRvtestsScoreOrCov_CombineAsPlaned.py --Output=combined.mCov.assoc.gz --Plan=planfile "--Input=test_output_*.MetaCov.assoc.gz"
     zcat combined.mCov.assoc.gz | bgzip > "${prefix}.MetaCov.assoc.gz"
     rm combined.mCov.assoc.gz
       metacovfn=$(dx upload --brief "${prefix}.MetaCov.assoc.gz")
      dx-jobutil-add-output output_files "${metacovfn}" --class=array:file
   fi
}

