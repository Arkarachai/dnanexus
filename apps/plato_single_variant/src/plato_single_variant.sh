#!/bin/bash
# plato_single_variant 0.0.1
# Generated by dx-app-wizard.
#
# Basic execution pattern: Your app will run on a single machine from
# beginning to end.
#
# Your job's input variables (if any) will be loaded as environment
# variables before this script runs.  Any array inputs will be loaded
# as bash arrays.
#
# Any code outside of main() (or any entry point you may add) is
# ALWAYS executed, followed by running the entry point itself.
#
# See https://wiki.dnanexus.com/Developer-Portal for tutorials on how
# to modify this file.

set -x
main() {
    
    
    echo "Value of input_plink_binary: '${input_plink_binary[@]}'"
    echo "Value of input_phenotype: '$input_phenotype'"
    echo "Value of plato_analysis_string: '$plato_analysis_string'"
    echo "Value of missingness: '$missingness'"
    echo "Value of input_continuous_covariate: '$input_continuous_covariate'"
    echo "Value of input_categorical_covariate: '$input_categorical_covariate'"
    echo "Value of input_samples: '$input_samples'"
    echo "Value of input_markers: '$input_markers'"
    echo "Value of maf_threshold: '$maf_threshold'"
    echo "Value of Association Type: '${association_type[@]}'"
    # The following line(s) use the dx command-line tool to download your file
    # inputs to the local file system using variable names for the filenames. To
    # recover the original filenames, you can use the output of "dx describe
    # "$variable" --name".
    #sudo mkdir /usr/share/biofilter
	#sudo chmod a+rwx /usr/share/biofilter
	
	
	# Download PLATO, PLINK, PLINK2	
	dx download "$DX_RESOURCES_ID:/PLATO/plato" -o /usr/bin/
	dx download "$DX_RESOURCES_ID:/Plink/plink" -o /usr/bin/
	dx download "$DX_RESOURCES_ID:/Plink/plink2" -o /usr/bin/
	sudo chmod a+rx /usr/bin/plato
	sudo chmod a+rx /usr/bin/plink
	sudo chmod a+rx /usr/bin/plink2
		
	
    
    input_dir="../.."
    # Download Phenotype files
    dx download "$input_phenotype" -o input_phenotype
    
    # Download Continous Covariate files
    if [ -n "$input_continuous_covariate" ]
    then
        dx download "$input_continuous_covariate" -o input_continuous_covariate
    fi
    
    # Download Categorical Covariate Files
    if [ -n "$input_categorical_covariate" ]
    then
        dx download "$input_categorical_covariate" -o input_categorical_covariate
		load_cat="load-categorical --file $input_dir/input_categorical_covariate --missing $missingness --extra-samples"
    fi
    
    # Download sample file if provided
    if [ -n "$input_samples" ]
    then
		dx download "$input_samples" -o input_samples
		plinkargs=" --keep input_samples"
    fi
    
    #Download marker file if provided
    if [ -n "$input_markers" ]
    then
        dx download "$input_markers" -o input_markers
		NF=$(head -n1 input_markers | wc -w)
	
	# Check the format marker files, If its RSID format then use --extract else for range format use --extract range
	if [[ "$NF" == 1 ]]
	then
		plinkargs="$plinkargs --extract input_markers"
	else
		plinkargs="$plinkargs --extract range input_markers"
	fi
    fi
    
    # MAF Threshold
    if [ -n "$maf_threshold" ]
    then
	plinkargs="$plinkargs --maf $maf_threshold"
    fi
    
    # Process Plink input files
    for i in ${!input_plink_binary[@]}
    do
        name=$(dx describe "${input_plink_binary[$i]}" --name)
	if [[ "$name" =~ \.bed$ ]]; then
		dx download "${input_plink_binary[$i]}" -o input_plink.bed
	elif [[ "$name" =~ \.bim$ ]]; then
    	dx download "${input_plink_binary[$i]}" -o input_plink.bim
	elif [[ "$name" =~ \.fam$ ]]; then
    	dx download "${input_plink_binary[$i]}" -o input_plink.fam
	fi
    done

    # Fill in your application code here.
    #
    # To report any recognized errors in the correct format in
    # $HOME/job_error.json and exit this script, you can use the
    # dx-jobutil-report-error utility as follows:
    #
    #   dx-jobutil-report-error "My error message"
    #
    # Note however that this entire bash script is executed with -e
    # when running in the cloud, so any line which returns a nonzero
    # exit code will prematurely exit the script; if no error was
    # reported in the job_error.json file, then the failure reason
    # will be AppInternalError with a generic error message.

    # The following line(s) use the utility dx-jobutil-add-output to format and
    # add output variables to your job's output as appropriate for the output
    # class.  Run "dx-jobutil-add-output -h" for more information on what it
    # does.
    LD_LIBRARY_PATH=/usr/local/lib/
    # perform any filtering with plink as specified by sample, marker lists
    # or maf threshold
    PLINK_CMD='plink2 '
    if [ -n "$plinkargs" ]; then
        mv input_plink.bed orig.bed
        mv input_plink.bim orig.bim
        mv input_plink.fam orig.fam
        plinkargs="$plinkargs --make-bed --out input_plink"
        $PLINK_CMD --bfile orig $plinkargs
    fi
    # create output directory.  Everything in this directory should
    # be returned after job is done.
    mkdir -p out/output_files
    cd out/output_files
    plato_analysis_string=$plato_analysis_string
   
	#Check if command-line string provided 
	if [[ -z "$plato_analysis_string" ]] 
	then
		# Regression Type
 		if [[ -n "$regression" ]] 
     	then
     		# Plato memory option. Use --lowmem by default
     		if [ "$mem" == true ]
     		then
				plato_analysis_string=" $regression --lowmem"
			else
				plato_analysis_string=" $regression"
			fi
     	fi
     	
		# Any covariates
     	if [[ -n "$covariates" ]]
     	then
        	plato_analysis_string="$plato_analysis_string --covariates $covariates"
     	fi
		
		# Type of analysis in PLATO
     	for i in ${association_type[@]}
     	do
     		if [[ "$i" == "PheWAS" ]]
     		then
        		plato_analysis_string="$plato_analysis_string --phewas"
     		elif [[ "$i" == "GWAS" ]]
     		then
        		plato_analysis_string=" $plato_analysis_string --outcome $outcome"
     		fi
     	done
     	
     	# Bonferoni or FDR correction
        if [[ -n "$correction" ]]
		then
			correction_val=$(echo ${correction[*]} | tr ' ' ',')	
			plato_analysis_string="$plato_analysis_string --correction $correction_val"
     	else
			plato_analysis_string="$plato_analysis_string"
		fi
		
		# If output file name provided
     	if [[ -n $output_filename ]]
     	then
        	plato_analysis_string=" $plato_analysis_string --output $output_filename"
        	outfile="$output_filename"
     	else
			plato_analysis_string=" $plato_analysis_string --output output.txt"
			outfile="output.txt"
     	fi
	else
		plato_analysis_string="$plato_analysis_string"
	fi     

	# Use all the core in AWS instance
	if ! [[ "$plato_analysis_string" =~ --threads ]]; then
		threads="--threads $(nproc)"
        analysis2=${plato_analysis_string/linear /linear $threads }
        analysis3=${analysis2/regress-auto /regress-auto $threads }
        analysis4=${analysis3/logistic /logistic $threads }
        plato_analysis_string=$analysis4
     fi

	# Plato command
    plato load-data \
    --bed $input_dir/input_plink.bed \
    --bim $input_dir/input_plink.bim \
    --fam $input_dir/input_plink.fam \
    recode-alleles --auto \
    load-trait \
    --extra-samples \
    --missing $missingness \
    --file $input_dir/input_phenotype \
    --file $input_dir/input_continuous_covariate \
    $load_cat \
    $plato_analysis_string
    
    # Filter out the results with MAF or Case filter provided.
    mkdir temp
    
    if [ -n "$maf_threshold" ] && [ -n "$case_threshold" ]
    then
		awk 'BEGIN{OFS=FS="\t"}{gsub(":","\t",$4)}1' ${outfile}  | sed 's/Var1_MAF/Var1_Allele\tMAF/g' | awk -v var1="$maf_threshold" 'BEGIN{OFS=FS="\t"}{if($5>var1) print $0}' > temp/${outfile}_maf_threshold
		cat temp/${outfile}_maf_threshold
		case_col=$(head -n1 temp/${outfile}_maf_threshold | tr '\t' '\n' | grep -n "Num_Cases" | cut -d":" -f1)
		awk -v var1="$case_col" -v var2="$case_threshold" 'BEGIN{OFS=FS="\t"}{if($var1>=var2)print $0}' temp/${outfile}_maf_threshold > $outfile
	elif [ -n "$maf_threshold" ]
	then
		awk 'BEGIN{OFS=FS="\t"}{gsub(":","\t",$4)}1' $outfile | sed 's/Var1_MAF/Var1_Allele\tMAF/g' | awk -v var1="$maf_threshold" 'BEGIN{OFS=FS="\t"}{if($5>var1) print $0}' > temp/${outfile}_maf_threshold
		cp temp/${outfile}_maf_threshold ${outfile}
	elif [ -n "$case_threshold" ]
	then
		awk 'BEGIN{OFS=FS="\t"}{gsub(":","\t",$4)}1' ${outfile} | sed 's/Var1_MAF/Var1_Allele\tMAF/g' > temp/${outfile}_maf
		case_col=$(head -n1 temp/${outfile}_maf | tr '\t' '\n' | grep -n "Num_Cases" | cut -d":" -f1)
		awk  -v var1="$case_col" -v var2="$case_threshold" 'BEGIN{OFS=FS="\t"}{if($var1>=var2)print $0}' temp/${outfile}_maf > ${outfile}
    fi
	rm -rf temp
    cd -

    # The following line(s) use the utility dx-jobutil-add-output to format and
    # add output variables to your job's output as appropriate for the output
    # class.  Run "dx-jobutil-add-output -h" for more information on what it
    # does.
    #echo $output_files
#    dx-upload-all-outputs
    files=out/output_files/*
    for f in $files; do
      echo "f=$f"
      fid=$(dx upload --brief $f)
      dx-jobutil-add-output output_files "$fid" --class=array:file
    done

}
