#!/bin/bash
# plato_single_variant 0.0.1
# Generated by dx-app-wizard.
#
# Basic execution pattern: Your app will run on a single machine from
# beginning to end.
#
# Your job's input variables (if any) will be loaded as environment
# variables before this script runs.  Any array inputs will be loaded
# as bash arrays.
#
# Any code outside of main() (or any entry point you may add) is
# ALWAYS executed, followed by running the entry point itself.
#
# See https://wiki.dnanexus.com/Developer-Portal for tutorials on how
# to modify this file.

set -x
main() {
    
    
    echo "Value of input_plink_binary: '${input_plink_binary[@]}'"
    echo "Value of input_phenotype: '$input_phenotype'"
    echo "Value of plato_analysis_string: '$plato_analysis_string'"
    echo "Value of missingness: '$missingness'"
    echo "Value of input_continuous_covariate: '$input_continuous_covariate'"
    echo "Value of input_categorical_covariate: '$input_categorical_covariate'"
    echo "Value of input_samples: '$input_samples'"
    echo "Value of input_markers: '$input_markers'"
    echo "Value of maf_threshold: '$maf_threshold'"
    echo "Value of Association Type: '${association_type[@]}'"
    echo "Value of Phenotype per job: '$split_phenotype'"
    
     # Process Plink input files
    for i in ${!input_plink_binary[@]}
    do
        name=$(dx describe "${input_plink_binary[$i]}" --name)
	if [[ "$name" =~ \.bed$ ]]; then
		bed_file="${input_plink_binary[$i]}" 
	elif [[ "$name" =~ \.bim$ ]]; then
    	bim_file="${input_plink_binary[$i]}"
	elif [[ "$name" =~ \.fam$ ]]; then
    	fam_file="${input_plink_binary[$i]}"
	fi
    done
    
    
    if [ $split_phenotype -gt 0 ]
    then
    	dx download "$input_phenotype" -o input_phenotype
    	# Get column numbers from the phenotype file
    	head -n 1 input_phenotype | sed 's/ /\t/g' | tr '\t' '\n' | awk '{ print FNR "\t" $0 }' | cut -f1 | tail -n+3  > pheno_col_index
		# Split the phenotypes
		split -l ${split_phenotype} -a 3 -d pheno_col_index pheno_job
		
    postprocess_arg=""
	for i in pheno_job* 
	do
		process_jobs[$i]=$(dx-jobutil-new-job plato_reg -ibed_file="${bed_file}" \
		-ibim_file="${bim_file}" \
		-ifam_file="${fam_file}" \
		-iinput_phenotype="${input_phenotype}" \
		-iinput_continuous_covariate="${input_continuous_covariate}" \
		-iinput_categorical_covariate="${input_categorical_covariate}" \
		-iregression="${regression}" \
		-ioutcome="${outcome}" \
		-imissingness="${missingness}" \
		-iinput_samples="${input_samples}" \
		-iinput_markers="${input_markers}" \
		-imaf_threshold="${maf_threshold}" \
		-iassociation_type="${association_type}" \
		-ipheno_col=$(cat $i | tr '\n' ',' | sed 's/,$//g') \
		-icovariates="${covariates}" \
		-ioutput_filename="${output_filename}" \
		-imem="${mem}" \
		-iplato_analysis_string="${plato_analysis_string}" \
		-icase_threshold="${case_threshold}" \
		-icorrection="${correction}")

		postprocess_arg="$postprocess_arg -iplato_out_files=${process_jobs[$i]}:plato_out -iplato_log_files=${process_jobs[$i]}:plato_log"
	done
	else
		process_jobs[$i]=$(dx-jobutil-new-job plato_reg -ibed_file="${bed_file}" \
		-ibim_file="${bim_file}" \
		-ifam_file="${fam_file}" \
		-iinput_phenotype="${input_phenotype}" \
		-iinput_continuous_covariate="${input_continuous_covariate}" \
		-iinput_categorical_covariate="${input_categorical_covariate}" \
		-iregression="${regression}" \
		-ioutcome="${outcome}" \
		-imissingness="${missingness}" \
		-iinput_samples="${input_samples}" \
		-iinput_markers="${input_markers}" \
		-imaf_threshold="${maf_threshold}" \
		-iassociation_type="${association_type}" \
		-ipheno_col=$(cat $i | tr '\n' ',' | sed 's/,$//g') \
		-icovariates="${covariates}" \
		-ioutput_filename="${output_filename}" \
		-imem="${mem}" \
		-iplato_analysis_string="${plato_analysis_string}" \
		-icase_threshold="${case_threshold}" \
		-icorrection="${correction}")

		postprocess_arg="$postprocess_arg -iplato_out_files=${process_jobs[$i]}:plato_out -iplato_log_files=${process_jobs[$i]}:plato_log"
	fi

	postprocess=$(dx-jobutil-new-job postprocess $postprocess_arg -ioutfile:string=$output_filename -icorrection=${correction} --depends-on ${process_jobs[@]})	

	dx-jobutil-add-output output_files "$postprocess:output_files" --class=jobref

}

plato_reg() {
	# The following line(s) use the dx command-line tool to download your file
	# inputs to the local file system using variable names for the filenames. To
	# recover the original filenames, you can use the output of "dx describe
	# "$variable" --name".

	dx download "$bed_file" -o input_plink.bed
	dx download "$bim_file" -o input_plink.bim
	dx download "$fam_file" -o input_plink.fam
	
	# Download PLATO, PLINK, PLINK2	
	LAB_RESOURCES="project-Bkp5fYQ0vqZfq1XXPkYK2p1z"
	dx download "$LAB_RESOURCES:/PLATO/plato" -f -o /usr/bin/
	dx download "$LAB_RESOURCES:/PLINK/plink" -f -o /usr/bin/
	dx download "$LAB_RESOURCES:/PLINK/plink2" -f -o /usr/bin/

	chmod a+rx /usr/bin/plato
	chmod a+rx /usr/bin/plink
	chmod a+rx /usr/bin/plink2

    
	input_dir="../.."
	# Download Phenotype files
	dx download "$input_phenotype" -o input_phenotype

	#Parallelize by phenotype
	if [[ $(echo ${pheno_col} | sed 's/,/ /g' | wc -w) -gt 0 ]]
	then
		cut -f1,2,"${pheno_col}" input_phenotype > input_phenotype_subset
		pheno_string="$input_dir/input_phenotype_subset"
	else
		pheno_string="$input_dir/input_phenotype"
	fi

	# Download Continous Covariate files
	if [ -n "$input_continuous_covariate" ]
	then
		dx download "$input_continuous_covariate" -o input_continuous_covariate
		load_cont="--file $input_dir/input_continuous_covariate"
	fi

	# Download Categorical Covariate Files
	if [ -n "$input_categorical_covariate" ]
	then
		dx download "$input_categorical_covariate" -o input_categorical_covariate
		load_cat="load-categorical --file $input_dir/input_categorical_covariate --missing $missingness --extra-samples"
	fi
    
	# Download sample file if provided
	if [ -n "$input_samples" ]
	then
		dx download "$input_samples" -o input_samples
		plinkargs=" --keep input_samples"
	fi
    
	#Download marker file if provided
	if [ -n "$input_markers" ]
	then
		dx download "$input_markers" -o input_markers
		NF=$(head -n1 input_markers | wc -w)

		# Check the format marker files, If its RSID format then use --extract else for range format use --extract range
		if [[ "$NF" == 1 ]]
		then
			plinkargs="$plinkargs --extract input_markers"
		else
			plinkargs="$plinkargs --extract range input_markers"
		fi
    fi

	# MAF Threshold
	if [ -n "$maf_threshold" ]
	then
		plinkargs="$plinkargs --maf $maf_threshold"
	fi

	# Fill in your application code here.
	#
	# To report any recognized errors in the correct format in
	# $HOME/job_error.json and exit this script, you can use the
	# dx-jobutil-report-error utility as follows:
	#
	#   dx-jobutil-report-error "My error message"
	#
	# Note however that this entire bash script is executed with -e
	# when running in the cloud, so any line which returns a nonzero
	# exit code will prematurely exit the script; if no error was
	# reported in the job_error.json file, then the failure reason
	# will be AppInternalError with a generic error message.

	# The following line(s) use the utility dx-jobutil-add-output to format and
	# add output variables to your job's output as appropriate for the output
	# class.  Run "dx-jobutil-add-output -h" for more information on what it
	# does.
	
	LD_LIBRARY_PATH=/usr/local/lib/
	# perform any filtering with plink as specified by sample, marker lists
	# or maf threshold
	
	PLINK_CMD='plink2 '
	if [ -n "$plinkargs" ]; then
		mv input_plink.bed orig.bed
		mv input_plink.bim orig.bim
		mv input_plink.fam orig.fam
		plinkargs="$plinkargs --make-bed --out input_plink"
		$PLINK_CMD --bfile orig $plinkargs
	fi
	# create output directory.  Everything in this directory should
	# be returned after job is done.
	mkdir -p out/output_files
	cd out/output_files
	plato_analysis_string=$plato_analysis_string

	#Check if command-line string provided 
	if [[ -z "$plato_analysis_string" ]] 
	then
		# Regression Type
		if [[ -n "$regression" ]] 
		then
			if [[ "$regression" == "firth" ]]
			then 
				regression="logistic --firth"
		fi
			# Plato memory option. Use --lowmem by default
			if [ "$mem" == true ]
			then
				plato_analysis_string=" $regression --lowmem"
			else
				plato_analysis_string=" $regression"
			fi
		fi
     	
		# Any covariates
		if [[ -n "$covariates" ]]
		then
			plato_analysis_string="$plato_analysis_string --covariates $covariates"
		fi

		# Type of analysis in PLATO
		for i in ${association_type[@]}
		do
			if [[ "$i" == "PheWAS" ]]
			then
				plato_analysis_string="$plato_analysis_string --phewas"
			elif [[ "$i" == "GWAS" ]]
			then
				plato_analysis_string=" $plato_analysis_string --outcome $outcome"
			fi
		done

		# Bonferoni or FDR correction
		if [[ -n "$correction" ]]
		then
			correction_val=$(echo ${correction[*]} | tr ' ' ',')	
			plato_analysis_string="$plato_analysis_string --correction $correction_val"
		else
			plato_analysis_string="$plato_analysis_string"
		fi

		# If output file name provided
		if [[ -n $output_filename ]]
		then
			plato_analysis_string=" $plato_analysis_string --output $output_filename"
			outfile="$output_filename"
		else
			plato_analysis_string=" $plato_analysis_string --output output.txt"
			outfile="output.txt"
		fi
	else
		plato_analysis_string="$plato_analysis_string"
	fi     

	# Use all the core in an AWS instance
	if ! [[ "$plato_analysis_string" =~ --threads ]] 
	then
		threads="--threads $(nproc)"
		analysis2=${plato_analysis_string/linear /linear $threads }
		analysis3=${analysis2/regress-auto /regress-auto $threads }
		analysis4=${analysis3/logistic /logistic $threads }
		plato_analysis_string=$analysis4
	fi

	# Plato command
	plato load-data \
	--bed $input_dir/input_plink.bed \
	--bim $input_dir/input_plink.bim \
	--fam $input_dir/input_plink.fam \
	recode-alleles --auto \
	load-trait \
	--extra-samples \
	--missing $missingness \
	--file $pheno_string \
	$load_cont \
	$load_cat \
	$plato_analysis_string || touch ${outfile}

	# Filter out the results with MAF or Case filter provided.
	mkdir temp

	if [ -n "$maf_threshold" ] && [ -n "$case_threshold" ]
	then
		awk 'BEGIN{OFS=FS="\t"}{gsub(":","\t",$4)}1' ${outfile}  | sed 's/Var1_MAF/Var1_Allele\tMAF/g' | awk -v var1="$maf_threshold" 'BEGIN{OFS=FS="\t"}{if($5>var1) print $0}' > temp/${outfile}_maf_threshold
		cat temp/${outfile}_maf_threshold
		case_col=$(head -n1 temp/${outfile}_maf_threshold | tr '\t' '\n' | grep -n "Num_Cases" | cut -d":" -f1)
		awk -v var1="$case_col" -v var2="$case_threshold" 'BEGIN{OFS=FS="\t"}{if($var1>=var2)print $0}' temp/${outfile}_maf_threshold > $outfile
	elif [ -n "$maf_threshold" ]
	then
		awk 'BEGIN{OFS=FS="\t"}{gsub(":","\t",$4)}1' $outfile | sed 's/Var1_MAF/Var1_Allele\tMAF/g' | awk -v var1="$maf_threshold" 'BEGIN{OFS=FS="\t"}{if($5>var1) print $0}' > temp/${outfile}_maf_threshold
		cp temp/${outfile}_maf_threshold ${outfile}
	elif [ -n "$case_threshold" ]
	then
		awk 'BEGIN{OFS=FS="\t"}{gsub(":","\t",$4)}1' ${outfile} | sed 's/Var1_MAF/Var1_Allele\tMAF/g' > temp/${outfile}_maf
		case_col=$(head -n1 temp/${outfile}_maf | tr '\t' '\n' | grep -n "Num_Cases" | cut -d":" -f1)
		awk  -v var1="$case_col" -v var2="$case_threshold" 'BEGIN{OFS=FS="\t"}{if($var1>=var2)print $0}' temp/${outfile}_maf > ${outfile}
	fi
	rm -rf temp
	
	# The following line(s) use the utility dx-jobutil-add-output to format and
	# add output variables to your job's output as appropriate for the output
	# class.  Run "dx-jobutil-add-output -h" for more information on what it
	# does.

	out=$(dx upload --brief ${outfile})
	log=$(dx upload --brief plato.log)

	dx-jobutil-add-output plato_out "${out}" --class=file
	dx-jobutil-add-output plato_log "${log}" --class=file
}

postprocess(){
	
	mkdir -p out/output_files
	
	for i in "${!plato_out_files[@]}"
	do
		dx download "${plato_out_files[$i]}" -o plato_out-$i
		head plato_out-$i
		mv plato_out-$i out/
	done

	for i in "${!plato_log_files[@]}"
	do
		dx download "${plato_log_files[$i]}" -o plato_log-$i
		head plato_log-$i
		mv plato_log-$i out/ 
	done

	cd out

	out_header=$(head -n1 plato_out-0 | sed 's/\t/\\t/g')

	if [[ -n "$outfile" ]]
	then
		out_name="${outfile}"
	else
		out_name="output.txt"
	fi

	pval_col=$(head -n1 plato_out-0 | tr '\t' '\n' | grep -n "Overall_Pval_(LRT)" | cut -d":" -f1)

	if [ "$correction" == "Bonferoni" ]
	then
		sort -s -m -gk$pval_col,$pval_col $(ls plato_out-*) | grep -v "Var1" \
		| cut -f1-$pval_col \
		| awk 'BEGIN{FS=OFS="\t"}{print $0, 1-(1-$var1)^var2}' \
		var1=$pval_col \
		var2=$(ls plato_out-* | xargs -n 1 tail -n+2  | wc -l) \
		| sed "1i $(echo ${out_header} | sed -E 's/Overall_Pval_adj_Bonferroni|Overall_Pval_adj_FDR//g')\tOverall_Pval_adj_Bonferroni" \
		> output_files/${out_name}
	elif [ "$correction" == "FDR" ]
	then
		pmax=1
		iter=0
		num_test=$(ls plato_out-* | xargs -n 1 tail -n+2  | wc -l)

		paste -d "\t" <(sort -s -m -gk$pval_col,$pval_col $(ls plato_out-*) | grep -v "Var1" | cut -f1-$pval_col) <(for i in $(sort -s -m -gk$pval_col,$pval_col $(ls plato_out-*) | grep -v "Var1" | cut -f$pval_col | tac); do pcal=$(echo "$(echo $i | sed -e 's/[eE]+*/\*10\^/')*${num_test}/(${num_test}-${iter})" | bc -l ); pmax=$(if [ $(echo "${pcal} < $(echo ${pmax} | sed -e 's/[eE]+*/\*10\^/' | bc -l)" | bc -l) == 1 ]; then echo $pcal ;else echo ${pmax};fi);iter=$(($iter+1)); pmax=$(printf %e ${pmax}); echo $pmax ;done | tac) | sed "1i $(echo ${out_header} | sed -E 's/Overall_Pval_adj_Bonferroni|Overall_Pval_adj_FDR//g')\tOverall_Pval_adj_FDR" > output_files/${out_name}
	else
		sort -s -m -gk$pval_col,$pval_col $(ls plato_out-*) | grep -v "Var1" | sed "1i ${out_header}" > output_files/${out_name}
	fi

	cat plato_log-* > output_files/${out_name}.log

	for i in output_files/*
	do
		out=$(dx upload --brief $i)
		dx-jobutil-add-output output_files "$out" --class=array:file
	done
	}
	

